{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr3OR/WWqr6SfRWUBX/F5b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nilo2022NITW/AIML/blob/main/Vectorisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeApTMIW648m"
      },
      "outputs": [],
      "source": [
        "import numpy     # it is an unofficial standard to use np for numpy\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy routines which allocate memory and fill arrays with value\n",
        "a = numpyp.zeros(4);                print(f\"np.zeros(4) :   a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")\n",
        "a = numpyp.zeros((4,));             print(f\"np.zeros(4,) :  a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")\n",
        "a = numpy.random.random_sample(4); print(f\"np.random.random_sample(4): a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "jRTtfgAR7Yxk",
        "outputId": "0e2093fa-fd80-4d85-b9d8-f5583387db90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-34762c0442ec>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# NumPy routines which allocate memory and fill arrays with value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpyp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"np.zeros(4) :   a = {a}, a shape = {a.shape}, a data type = {a.dtype}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpyp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"np.zeros(4,) :  a = {a}, a shape = {a.shape}, a data type = {a.dtype}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"np.random.random_sample(4): a = {a}, a shape = {a.shape}, a data type = {a.dtype}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'numpyp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy routines which allocate memory and fill arrays with value but do not accept shape as input argument\n",
        "a = np.arange(4.);              print(f\"np.arange(4.):     a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")\n",
        "a = np.random.rand(4);          print(f\"np.random.rand(4): a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")"
      ],
      "metadata": {
        "id": "oWBO-K3m7h3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy routines which allocate memory and fill with user specified values\n",
        "a = np.array([5,4,3,2]);  print(f\"np.array([5,4,3,2]):  a = {a},     a shape = {a.shape}, a data type = {a.dtype}\")\n",
        "a = np.array([5.,4,3,2]); print(f\"np.array([5.,4,3,2]): a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")"
      ],
      "metadata": {
        "id": "GSoCG8mT7mgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vector indexing operations on 1-D vectors\n",
        "a = np.arange(10)\n",
        "print(a)\n",
        "\n",
        "#access an element\n",
        "print(f\"a[2].shape: {a[2].shape} a[2]  = {a[2]}, Accessing an element returns a scalar\")\n",
        "\n",
        "# access the last element, negative indexes count from the end\n",
        "print(f\"a[-1] = {a[-1]}\")\n",
        "\n",
        "#indexs must be within the range of the vector or they will produce and error\n",
        "try:\n",
        "    c = a[10]\n",
        "except Exception as e:\n",
        "    print(\"The error message you'll see is:\")\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "c37J377O7tC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vector slicing operations\n",
        "a = np.arange(10)\n",
        "print(f\"a         = {a}\")\n",
        "\n",
        "#access 5 consecutive elements (start:stop:step)\n",
        "c = a[2:7:1];     print(\"a[2:7:1] = \", c)\n",
        "\n",
        "# access 3 elements separated by two\n",
        "c = a[2:7:2];     print(\"a[2:7:2] = \", c)\n",
        "\n",
        "# access all elements index 3 and above\n",
        "c = a[3:];        print(\"a[3:]    = \", c)\n",
        "\n",
        "# access all elements below index 3\n",
        "c = a[:3];        print(\"a[:3]    = \", c)\n",
        "\n",
        "# access all elements\n",
        "c = a[:];         print(\"a[:]     = \", c)"
      ],
      "metadata": {
        "id": "Di7r2xYZ7uD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2,3,4])\n",
        "print(f\"a             : {a}\")\n",
        "# negate elements of a\n",
        "b = -a\n",
        "print(f\"b = -a        : {b}\")\n",
        "\n",
        "# sum all elements of a, returns a scalar\n",
        "b = np.sum(a)\n",
        "print(f\"b = np.sum(a) : {b}\")\n",
        "\n",
        "b = np.mean(a)\n",
        "print(f\"b = np.mean(a): {b}\")\n",
        "\n",
        "b = a**2\n",
        "print(f\"b = a**2      : {b}\")"
      ],
      "metadata": {
        "id": "Ax5hd7Gp7yeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([ 1, 2, 3, 4])\n",
        "b = np.array([-1,-2, 3, 4])\n",
        "print(f\"Binary operators work element wise: {a + b}\")"
      ],
      "metadata": {
        "id": "aTqzlXF_74zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try a mismatched vector operation\n",
        "c = np.array([1, 2])\n",
        "try:\n",
        "    d = a + c\n",
        "except Exception as e:\n",
        "    print(\"The error message you'll see is:\")\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "0_4dREPT75zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1, 2, 3, 4])\n",
        "\n",
        "# multiply a by a scalar\n",
        "b = 5 * a\n",
        "print(f\"b = 5 * a : {b}\")"
      ],
      "metadata": {
        "id": "T6d778Be7-Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_dot(a, b):\n",
        "    \"\"\"\n",
        "   Compute the dot product of two vectors\n",
        "\n",
        "    Args:\n",
        "      a (ndarray (n,)):  input vector\n",
        "      b (ndarray (n,)):  input vector with same dimension as a\n",
        "\n",
        "    Returns:\n",
        "      x (scalar):\n",
        "    \"\"\"\n",
        "    x=0\n",
        "    for i in range(a.shape[0]):\n",
        "        x = x + a[i] * b[i]\n",
        "    return x"
      ],
      "metadata": {
        "id": "UTAk3NAH8EZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test 1-D\n",
        "a = np.array([1, 2, 3, 4])\n",
        "b = np.array([-1, 4, 3, 2])\n",
        "print(f\"my_dot(a, b) = {my_dot(a, b)}\")"
      ],
      "metadata": {
        "id": "21OoTaf18F8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test 1-D\n",
        "a = np.array([1, 2, 3, 4])\n",
        "b = np.array([-1, 4, 3, 2])\n",
        "c = np.dot(a, b)\n",
        "print(f\"NumPy 1-D np.dot(a, b) = {c}, np.dot(a, b).shape = {c.shape} \")\n",
        "c = np.dot(b, a)\n",
        "print(f\"NumPy 1-D np.dot(b, a) = {c}, np.dot(a, b).shape = {c.shape} \")\n",
        "np.random.seed(1)\n",
        "a = np.random.rand(10000000)  # very large arrays\n",
        "b = np.random.rand(10000000)\n",
        "\n",
        "tic = time.time()  # capture start time\n",
        "c = np.dot(a, b)\n",
        "toc = time.time()  # capture end time\n",
        "\n",
        "print(f\"np.dot(a, b) =  {c:.4f}\")\n",
        "print(f\"Vectorized version duration: {1000*(toc-tic):.4f} ms \")\n",
        "\n",
        "tic = time.time()  # capture start time\n",
        "c = my_dot(a,b)\n",
        "toc = time.time()  # capture end time\n",
        "\n",
        "print(f\"my_dot(a, b) =  {c:.4f}\")\n",
        "print(f\"loop version duration: {1000*(toc-tic):.4f} ms \")\n",
        "\n",
        "del(a);del(b)  #remove these big arrays from memory"
      ],
      "metadata": {
        "id": "_tIFjMLC8Ibc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show common Course 1 example\n",
        "X = np.array([[1],[2],[3],[4]])\n",
        "w = np.array([2])\n",
        "c = np.dot(X[1], w)\n",
        "\n",
        "print(f\"X[1] has shape {X[1].shape}\")\n",
        "print(f\"w has shape {w.shape}\")\n",
        "print(f\"c has shape {c.shape}\")"
      ],
      "metadata": {
        "id": "wZZj-WkC8Q91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.zeros((1, 5))\n",
        "print(f\"a shape = {a.shape}, a = {a}\")\n",
        "\n",
        "a = np.zeros((2, 1))\n",
        "print(f\"a shape = {a.shape}, a = {a}\")\n",
        "\n",
        "a = np.random.random_sample((1, 1))\n",
        "print(f\"a shape = {a.shape}, a = {a}\")"
      ],
      "metadata": {
        "id": "YmSdfS4P8KdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy routines which allocate memory and fill with user specified values\n",
        "a = np.array([[5], [4], [3]]);   print(f\" a shape = {a.shape}, np.array: a = {a}\")\n",
        "a = np.array([[5],   # One can also\n",
        "              [4],   # separate values\n",
        "              [3]]); #into separate rows\n",
        "print(f\" a shape = {a.shape}, np.array: a = {a}\")"
      ],
      "metadata": {
        "id": "r664f6pN8aX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vector indexing operations on matrices\n",
        "a = np.arange(6).reshape(-1, 2)   #reshape is a convenient way to create matrices\n",
        "print(f\"a.shape: {a.shape}, \\na= {a}\")\n",
        "\n",
        "#access an element\n",
        "print(f\"\\na[2,0].shape:   {a[2, 0].shape}, a[2,0] = {a[2, 0]},     type(a[2,0]) = {type(a[2, 0])} Accessing an element returns a scalar\\n\")\n",
        "\n",
        "#access a row\n",
        "print(f\"a[2].shape:   {a[2].shape}, a[2]   = {a[2]}, type(a[2])   = {type(a[2])}\")"
      ],
      "metadata": {
        "id": "rXN1k67T8dix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vector 2-D slicing operations\n",
        "a = np.arange(20).reshape(-1, 10)\n",
        "print(f\"a = \\n{a}\")\n",
        "\n",
        "#access 5 consecutive elements (start:stop:step)\n",
        "print(\"a[0, 2:7:1] = \", a[0, 2:7:1], \",  a[0, 2:7:1].shape =\", a[0, 2:7:1].shape, \"a 1-D array\")\n",
        "\n",
        "#access 5 consecutive elements (start:stop:step) in two rows\n",
        "print(\"a[:, 2:7:1] = \\n\", a[:, 2:7:1], \",  a[:, 2:7:1].shape =\", a[:, 2:7:1].shape, \"a 2-D array\")\n",
        "\n",
        "# access all elements\n",
        "print(\"a[:,:] = \\n\", a[:,:], \",  a[:,:].shape =\", a[:,:].shape)\n",
        "\n",
        "# access all elements in one row (very common usage)\n",
        "print(\"a[1,:] = \", a[1,:], \",  a[1,:].shape =\", a[1,:].shape, \"a 1-D array\")\n",
        "# same as\n",
        "print(\"a[1]   = \", a[1],   \",  a[1].shape   =\", a[1].shape, \"a 1-D array\")\n"
      ],
      "metadata": {
        "id": "Cfx4iaWX8gjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Problem Statement\n",
        "You will use the motivating example of housing price prediction. The training dataset contains three examples with four features (size, bedrooms, floors and, age) shown in the table below. Note that, unlike the earlier labs, size is in sqft rather than 1000 sqft. This causes an issue, which you will solve in the next lab!\n",
        "\n",
        "Size (sqft)\tNumber of Bedrooms\tNumber of floors\tAge of Home\tPrice (1000s dollars)\n",
        "2104\t5\t1\t45\t460\n",
        "1416\t3\t2\t40\t232\n",
        "852\t2\t1\t35\t178\n",
        "You will build a linear regression model using these values so you can then predict the price for other houses. For example, a house with 1200 sqft, 3 bedrooms, 1 floor, 40 years old.\n",
        "\n",
        "Please run the following code cell to create your X_train and y_train variables."
      ],
      "metadata": {
        "id": "v0E_f_sZrlL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
        "y_train = np.array([460, 232, 178])"
      ],
      "metadata": {
        "id": "etBlU15Xrtbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data is stored in numpy array/matrix\n",
        "print(f\"X Shape: {X_train.shape}, X Type:{type(X_train)})\")\n",
        "print(X_train)\n",
        "print(f\"y Shape: {y_train.shape}, y Type:{type(y_train)})\")\n",
        "print(y_train)"
      ],
      "metadata": {
        "id": "rXVKAJk2rwvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_init = 785.1811367994083\n",
        "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
        "print(f\"w_init shape: {w_init.shape}, b_init type: {type(b_init)}\")"
      ],
      "metadata": {
        "id": "2ZRIhhylr2aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single_loop(x, w, b):\n",
        "    \"\"\"\n",
        "    single predict using linear regression\n",
        "\n",
        "    Args:\n",
        "      x (ndarray): Shape (n,) example with multiple features\n",
        "      w (ndarray): Shape (n,) model parameters\n",
        "      b (scalar):  model parameter\n",
        "\n",
        "    Returns:\n",
        "      p (scalar):  prediction\n",
        "    \"\"\"\n",
        "    n = x.shape[0]\n",
        "    p = 0\n",
        "    for i in range(n):\n",
        "        p_i = x[i] * w[i]\n",
        "        p = p + p_i\n",
        "    p = p + b\n",
        "    return p"
      ],
      "metadata": {
        "id": "lPtGqEArr2_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get a row from our training data\n",
        "x_vec = X_train[0,:]\n",
        "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
        "\n",
        "# make a prediction\n",
        "f_wb = predict_single_loop(x_vec, w_init, b_init)\n",
        "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
      ],
      "metadata": {
        "id": "JWJgXMaRr56C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, w, b):\n",
        "    \"\"\"\n",
        "    single predict using linear regression\n",
        "    Args:\n",
        "      x (ndarray): Shape (n,) example with multiple features\n",
        "      w (ndarray): Shape (n,) model parameters\n",
        "      b (scalar):             model parameter\n",
        "\n",
        "    Returns:\n",
        "      p (scalar):  prediction\n",
        "    \"\"\"\n",
        "    p = np.dot(x, w) + b\n",
        "    return p"
      ],
      "metadata": {
        "id": "JBt1Bl4Kr_3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get a row from our training data\n",
        "x_vec = X_train[0,:]\n",
        "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
        "\n",
        "# make a prediction\n",
        "f_wb = predict(x_vec,w_init, b_init)\n",
        "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
      ],
      "metadata": {
        "id": "eUuh6iVMsK1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(X, y, w, b):\n",
        "    \"\"\"\n",
        "    compute cost\n",
        "    Args:\n",
        "      X (ndarray (m,n)): Data, m examples with n features\n",
        "      y (ndarray (m,)) : target values\n",
        "      w (ndarray (n,)) : model parameters\n",
        "      b (scalar)       : model parameter\n",
        "\n",
        "    Returns:\n",
        "      cost (scalar): cost\n",
        "    \"\"\"\n",
        "    m = X.shape[0]\n",
        "    cost = 0.0\n",
        "    for i in range(m):\n",
        "        f_wb_i = np.dot(X[i], w) + b           #(n,)(n,) = scalar (see np.dot)\n",
        "        cost = cost + (f_wb_i - y[i])**2       #scalar\n",
        "    cost = cost / (2 * m)                      #scalar\n",
        "    return cost"
      ],
      "metadata": {
        "id": "BvBi2tOjsO0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and display cost using our pre-chosen optimal parameters.\n",
        "cost = compute_cost(X_train, y_train, w_init, b_init)\n",
        "print(f'Cost at optimal w : {cost}')"
      ],
      "metadata": {
        "id": "3U9Ne0ZEtg39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 Gradient Descent With Multiple Variables\n",
        "Gradient descent for multiple variables:\n",
        "\n",
        "repeat} until convergence:{𝑤𝑗=𝑤𝑗−𝛼∂𝐽(𝐰,𝑏)∂𝑤𝑗𝑏  =𝑏−𝛼∂𝐽(𝐰,𝑏)∂𝑏for j = 0..n-1(5)\n",
        "where, n is the number of features, parameters  𝑤𝑗\n",
        " ,  𝑏\n",
        " , are updated simultaneously and where\n",
        "\n",
        "∂𝐽(𝐰,𝑏)∂𝑤𝑗∂𝐽(𝐰,𝑏)∂𝑏=1𝑚∑𝑖=0𝑚−1(𝑓𝐰,𝑏(𝐱(𝑖))−𝑦(𝑖))𝑥(𝑖)𝑗=1𝑚∑𝑖=0𝑚−1(𝑓𝐰,𝑏(𝐱(𝑖))−𝑦(𝑖))(6)(7)\n",
        "m is the number of training examples in the data set\n",
        "𝑓𝐰,𝑏(𝐱(𝑖))\n",
        "  is the model's prediction, while  𝑦(𝑖)\n",
        "  is the target value"
      ],
      "metadata": {
        "id": "2Ec761kfth6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(X, y, w, b):\n",
        "    \"\"\"\n",
        "    Computes the gradient for linear regression\n",
        "    Args:\n",
        "      X (ndarray (m,n)): Data, m examples with n features\n",
        "      y (ndarray (m,)) : target values\n",
        "      w (ndarray (n,)) : model parameters\n",
        "      b (scalar)       : model parameter\n",
        "\n",
        "    Returns:\n",
        "      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w.\n",
        "      dj_db (scalar):       The gradient of the cost w.r.t. the parameter b.\n",
        "    \"\"\"\n",
        "    m,n = X.shape           #(number of examples, number of features)\n",
        "    dj_dw = np.zeros((n,))\n",
        "    dj_db = 0.\n",
        "\n",
        "    for i in range(m):\n",
        "        err = (np.dot(X[i], w) + b) - y[i]\n",
        "        for j in range(n):\n",
        "            dj_dw[j] = dj_dw[j] + err * X[i, j]\n",
        "        dj_db = dj_db + err\n",
        "    dj_dw = dj_dw / m\n",
        "    dj_db = dj_db / m\n",
        "\n",
        "    return dj_db, dj_dw"
      ],
      "metadata": {
        "id": "GOPuUgCHtmFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute and display gradient\n",
        "tmp_dj_db, tmp_dj_dw = compute_gradient(X_train, y_train, w_init, b_init)\n",
        "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
        "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
      ],
      "metadata": {
        "id": "S6LhbLyet2M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient descent with multiple variables\n"
      ],
      "metadata": {
        "id": "qH5R-LEit9GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters):\n",
        "    \"\"\"\n",
        "    Performs batch gradient descent to learn w and b. Updates w and b by taking\n",
        "    num_iters gradient steps with learning rate alpha\n",
        "\n",
        "    Args:\n",
        "      X (ndarray (m,n))   : Data, m examples with n features\n",
        "      y (ndarray (m,))    : target values\n",
        "      w_in (ndarray (n,)) : initial model parameters\n",
        "      b_in (scalar)       : initial model parameter\n",
        "      cost_function       : function to compute cost\n",
        "      gradient_function   : function to compute the gradient\n",
        "      alpha (float)       : Learning rate\n",
        "      num_iters (int)     : number of iterations to run gradient descent\n",
        "\n",
        "    Returns:\n",
        "      w (ndarray (n,)) : Updated values of parameters\n",
        "      b (scalar)       : Updated value of parameter\n",
        "      \"\"\"\n",
        "\n",
        "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
        "    J_history = []\n",
        "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
        "    b = b_in\n",
        "\n",
        "    for i in range(num_iters):\n",
        "\n",
        "        # Calculate the gradient and update the parameters\n",
        "        dj_db,dj_dw = gradient_function(X, y, w, b)   ##None\n",
        "\n",
        "        # Update Parameters using w, b, alpha and gradient\n",
        "        w = w - alpha * dj_dw               ##None\n",
        "        b = b - alpha * dj_db               ##None\n",
        "\n",
        "        # Save cost J at each iteration\n",
        "        if i<100000:      # prevent resource exhaustion\n",
        "            J_history.append( cost_function(X, y, w, b))\n",
        "\n",
        "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
        "        if i% math.ceil(num_iters / 10) == 0:\n",
        "            print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")\n",
        "\n",
        "    return w, b, J_history #return final w,b and J history for graphing"
      ],
      "metadata": {
        "id": "O3F6A8ZMt77j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize parameters\n",
        "initial_w = np.zeros_like(w_init)\n",
        "initial_b = 0.\n",
        "# some gradient descent settings\n",
        "iterations = 1000\n",
        "alpha = 5.0e-7\n",
        "# run gradient descent\n",
        "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b,\n",
        "                                                    compute_cost, compute_gradient,\n",
        "                                                    alpha, iterations)\n",
        "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
        "m,_ = X_train.shape\n",
        "for i in range(m):\n",
        "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
      ],
      "metadata": {
        "id": "OaeKnGsnuFgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot cost versus iteration\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12, 4))\n",
        "ax1.plot(J_hist)\n",
        "ax2.plot(100 + np.arange(len(J_hist[100:])), J_hist[100:])\n",
        "ax1.set_title(\"Cost vs. iteration\");  ax2.set_title(\"Cost vs. iteration (tail)\")\n",
        "ax1.set_ylabel('Cost')             ;  ax2.set_ylabel('Cost')\n",
        "ax1.set_xlabel('iteration step')   ;  ax2.set_xlabel('iteration step')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uHb0yMsouGUV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}